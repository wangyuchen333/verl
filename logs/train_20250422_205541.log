2025-04-22 20:55:47,925	INFO worker.py:1832 -- Started a local Ray instance. View the dashboard at [1m[32m127.0.0.1:8266 [39m[22m
[36m(TaskRunner pid=2077808)[0m {'actor_rollout_ref': {'actor': {'checkpoint': {'contents': ['model',
[36m(TaskRunner pid=2077808)[0m                                                              'optimizer',
[36m(TaskRunner pid=2077808)[0m                                                              'extra']},
[36m(TaskRunner pid=2077808)[0m                                  'clip_ratio': 0.2,
[36m(TaskRunner pid=2077808)[0m                                  'clip_ratio_c': 3.0,
[36m(TaskRunner pid=2077808)[0m                                  'clip_ratio_high': 0.2,
[36m(TaskRunner pid=2077808)[0m                                  'clip_ratio_low': 0.2,
[36m(TaskRunner pid=2077808)[0m                                  'entropy_coeff': 0,
[36m(TaskRunner pid=2077808)[0m                                  'fsdp_config': {'fsdp_dtype': 'float16',
[36m(TaskRunner pid=2077808)[0m                                                  'fsdp_size': -1,
[36m(TaskRunner pid=2077808)[0m                                                  'optimizer_offload': False,
[36m(TaskRunner pid=2077808)[0m                                                  'param_offload': True,
[36m(TaskRunner pid=2077808)[0m                                                  'wrap_policy': {'min_num_params': 0}},
[36m(TaskRunner pid=2077808)[0m                                  'grad_clip': 1.0,
[36m(TaskRunner pid=2077808)[0m                                  'kl_loss_coef': 0.001,
[36m(TaskRunner pid=2077808)[0m                                  'kl_loss_type': 'low_var_kl',
[36m(TaskRunner pid=2077808)[0m                                  'loss_agg_mode': 'token-mean',
[36m(TaskRunner pid=2077808)[0m                                  'optim': {'lr': 1e-06,
[36m(TaskRunner pid=2077808)[0m                                            'lr_warmup_steps': -1,
[36m(TaskRunner pid=2077808)[0m                                            'lr_warmup_steps_ratio': 0.0,
[36m(TaskRunner pid=2077808)[0m                                            'min_lr_ratio': None,
[36m(TaskRunner pid=2077808)[0m                                            'total_training_steps': -1,
[36m(TaskRunner pid=2077808)[0m                                            'warmup_style': 'constant',
[36m(TaskRunner pid=2077808)[0m                                            'weight_decay': 0.01},
[36m(TaskRunner pid=2077808)[0m                                  'ppo_epochs': 1,
[36m(TaskRunner pid=2077808)[0m                                  'ppo_max_token_len_per_gpu': 16384,
[36m(TaskRunner pid=2077808)[0m                                  'ppo_micro_batch_size': None,
[36m(TaskRunner pid=2077808)[0m                                  'ppo_micro_batch_size_per_gpu': 16,
[36m(TaskRunner pid=2077808)[0m                                  'ppo_mini_batch_size': 32,
[36m(TaskRunner pid=2077808)[0m                                  'shuffle': False,
[36m(TaskRunner pid=2077808)[0m                                  'strategy': 'fsdp',
[36m(TaskRunner pid=2077808)[0m                                  'ulysses_sequence_parallel_size': 1,
[36m(TaskRunner pid=2077808)[0m                                  'use_dynamic_bsz': False,
[36m(TaskRunner pid=2077808)[0m                                  'use_kl_loss': False,
[36m(TaskRunner pid=2077808)[0m                                  'use_torch_compile': True},
[36m(TaskRunner pid=2077808)[0m                        'hybrid_engine': True,
[36m(TaskRunner pid=2077808)[0m                        'model': {'enable_gradient_checkpointing': True,
[36m(TaskRunner pid=2077808)[0m                                  'external_lib': None,
[36m(TaskRunner pid=2077808)[0m                                  'override_config': {},
[36m(TaskRunner pid=2077808)[0m                                  'path': '/home/wangyc/verl/Qwen/Qwen2___5-7B-Instruct',
[36m(TaskRunner pid=2077808)[0m                                  'use_liger': False,
[36m(TaskRunner pid=2077808)[0m                                  'use_remove_padding': True},
[36m(TaskRunner pid=2077808)[0m                        'ref': {'fsdp_config': {'param_offload': True,
[36m(TaskRunner pid=2077808)[0m                                                'wrap_policy': {'min_num_params': 0}},
[36m(TaskRunner pid=2077808)[0m                                'log_prob_max_token_len_per_gpu': 16384,
[36m(TaskRunner pid=2077808)[0m                                'log_prob_micro_batch_size': None,
[36m(TaskRunner pid=2077808)[0m                                'log_prob_micro_batch_size_per_gpu': 32,
[36m(TaskRunner pid=2077808)[0m                                'log_prob_use_dynamic_bsz': False,
[36m(TaskRunner pid=2077808)[0m                                'strategy': 'fsdp',
[36m(TaskRunner pid=2077808)[0m                                'ulysses_sequence_parallel_size': 1},
[36m(TaskRunner pid=2077808)[0m                        'rollout': {'disable_log_stats': True,
[36m(TaskRunner pid=2077808)[0m                                    'do_sample': True,
[36m(TaskRunner pid=2077808)[0m                                    'dtype': 'bfloat16',
[36m(TaskRunner pid=2077808)[0m                                    'enable_chunked_prefill': True,
[36m(TaskRunner pid=2077808)[0m                                    'enforce_eager': True,
[36m(TaskRunner pid=2077808)[0m                                    'engine_kwargs': {'swap_space': None},
[36m(TaskRunner pid=2077808)[0m                                    'free_cache_engine': True,
[36m(TaskRunner pid=2077808)[0m                                    'gpu_memory_utilization': 0.6,
[36m(TaskRunner pid=2077808)[0m                                    'ignore_eos': False,
[36m(TaskRunner pid=2077808)[0m                                    'load_format': 'dummy_dtensor',
[36m(TaskRunner pid=2077808)[0m                                    'log_prob_max_token_len_per_gpu': 16384,
[36m(TaskRunner pid=2077808)[0m                                    'log_prob_micro_batch_size': None,
[36m(TaskRunner pid=2077808)[0m                                    'log_prob_micro_batch_size_per_gpu': 32,
[36m(TaskRunner pid=2077808)[0m                                    'log_prob_use_dynamic_bsz': False,
[36m(TaskRunner pid=2077808)[0m                                    'max_model_len': None,
[36m(TaskRunner pid=2077808)[0m                                    'max_num_batched_tokens': 8192,
[36m(TaskRunner pid=2077808)[0m                                    'max_num_seqs': 1024,
[36m(TaskRunner pid=2077808)[0m                                    'n': 6,
[36m(TaskRunner pid=2077808)[0m                                    'name': 'vllm',
[36m(TaskRunner pid=2077808)[0m                                    'prompt_length': 1024,
[36m(TaskRunner pid=2077808)[0m                                    'response_length': 1024,
[36m(TaskRunner pid=2077808)[0m                                    'temperature': 1.0,
[36m(TaskRunner pid=2077808)[0m                                    'tensor_model_parallel_size': 2,
[36m(TaskRunner pid=2077808)[0m                                    'top_k': -1,
[36m(TaskRunner pid=2077808)[0m                                    'top_p': 1,
[36m(TaskRunner pid=2077808)[0m                                    'use_fire_sampling': False,
[36m(TaskRunner pid=2077808)[0m                                    'val_kwargs': {'do_sample': False,
[36m(TaskRunner pid=2077808)[0m                                                   'n': 1,
[36m(TaskRunner pid=2077808)[0m                                                   'temperature': 0,
[36m(TaskRunner pid=2077808)[0m                                                   'top_k': -1,
[36m(TaskRunner pid=2077808)[0m                                                   'top_p': 1.0}}},
[36m(TaskRunner pid=2077808)[0m  'algorithm': {'adv_estimator': 'grpo',
[36m(TaskRunner pid=2077808)[0m                'gamma': 1.0,
[36m(TaskRunner pid=2077808)[0m                'kl_ctrl': {'horizon': 10000,
[36m(TaskRunner pid=2077808)[0m                            'kl_coef': 0.0,
[36m(TaskRunner pid=2077808)[0m DeprecationWarning: `ray.state.available_resources_per_node` is a private attribute and access will be removed in a future Ray version.
[36m(TaskRunner pid=2077808)[0m WARNING:2025-04-22 20:55:58,613:Waiting for register center actor mYLNU5_register_center to be ready. Elapsed time: 0 seconds out of 300 seconds.
[36m(WorkerDict pid=2087560)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
[36m(WorkerDict pid=2087560)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[36m(WorkerDict pid=2087560)[0m Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[36m(TaskRunner pid=2077808)[0m                            'target_kl': 0.1,
[36m(TaskRunner pid=2077808)[0m                            'type': 'fixed'},
[36m(TaskRunner pid=2077808)[0m                'kl_penalty': 'kl',
[36m(TaskRunner pid=2077808)[0m                'lam': 1.0,
[36m(TaskRunner pid=2077808)[0m                'norm_adv_by_std_in_grpo': True,
[36m(TaskRunner pid=2077808)[0m                'use_kl_in_reward': False},
[36m(TaskRunner pid=2077808)[0m  'critic': {'checkpoint': {'contents': ['model', 'optimizer', 'extra']},
[36m(TaskRunner pid=2077808)[0m             'cliprange_value': 0.5,
[36m(TaskRunner pid=2077808)[0m             'forward_max_token_len_per_gpu': 32768,
[36m(TaskRunner pid=2077808)[0m             'forward_micro_batch_size': None,
[36m(TaskRunner pid=2077808)[0m             'forward_micro_batch_size_per_gpu': None,
[36m(TaskRunner pid=2077808)[0m             'grad_clip': 1.0,
[36m(TaskRunner pid=2077808)[0m             'model': {'enable_gradient_checkpointing': True,
[36m(TaskRunner pid=2077808)[0m                       'external_lib': None,
[36m(TaskRunner pid=2077808)[0m                       'fsdp_config': {'fsdp_size': -1,
[36m(TaskRunner pid=2077808)[0m                                       'optimizer_offload': False,
[36m(TaskRunner pid=2077808)[0m                                       'param_offload': False,
[36m(TaskRunner pid=2077808)[0m                                       'wrap_policy': {'min_num_params': 0}},
[36m(TaskRunner pid=2077808)[0m                       'override_config': {},
[36m(TaskRunner pid=2077808)[0m                       'path': '~/models/deepseek-llm-7b-chat',
[36m(TaskRunner pid=2077808)[0m                       'tokenizer_path': '/home/wangyc/verl/Qwen/Qwen2___5-7B-Instruct',
[36m(TaskRunner pid=2077808)[0m                       'use_remove_padding': False},
[36m(TaskRunner pid=2077808)[0m             'optim': {'lr': 1e-05,
[36m(TaskRunner pid=2077808)[0m                       'lr_warmup_steps_ratio': 0.0,
[36m(TaskRunner pid=2077808)[0m                       'min_lr_ratio': None,
[36m(TaskRunner pid=2077808)[0m                       'total_training_steps': -1,
[36m(TaskRunner pid=2077808)[0m                       'warmup_style': 'constant',
[36m(TaskRunner pid=2077808)[0m                       'weight_decay': 0.01},
[36m(TaskRunner pid=2077808)[0m             'ppo_epochs': 1,
[36m(TaskRunner pid=2077808)[0m             'ppo_max_token_len_per_gpu': 32768,
[36m(TaskRunner pid=2077808)[0m             'ppo_micro_batch_size': None,
[36m(TaskRunner pid=2077808)[0m             'ppo_micro_batch_size_per_gpu': None,
[36m(TaskRunner pid=2077808)[0m             'ppo_mini_batch_size': 32,
[36m(TaskRunner pid=2077808)[0m             'rollout_n': 6,
[36m(TaskRunner pid=2077808)[0m             'shuffle': False,
[36m(TaskRunner pid=2077808)[0m             'strategy': 'fsdp',
[36m(TaskRunner pid=2077808)[0m             'ulysses_sequence_parallel_size': 1,
[36m(TaskRunner pid=2077808)[0m             'use_dynamic_bsz': False},
[36m(TaskRunner pid=2077808)[0m  'custom_reward_function': {'name': 'compute_score', 'path': None},
[36m(TaskRunner pid=2077808)[0m  'data': {'custom_cls': {'name': None, 'path': None},
[36m(TaskRunner pid=2077808)[0m           'filter_overlong_prompts': False,
[36m(TaskRunner pid=2077808)[0m           'filter_overlong_prompts_workers': 1,
[36m(TaskRunner pid=2077808)[0m           'image_key': 'images',
[36m(TaskRunner pid=2077808)[0m           'max_prompt_length': 1024,
[36m(TaskRunner pid=2077808)[0m           'max_response_length': 1024,
[36m(TaskRunner pid=2077808)[0m           'prompt_key': 'prompt',
[36m(TaskRunner pid=2077808)[0m           'return_raw_chat': False,
[36m(TaskRunner pid=2077808)[0m           'return_raw_input_ids': False,
[36m(TaskRunner pid=2077808)[0m           'reward_fn_key': 'data_source',
[36m(TaskRunner pid=2077808)[0m           'shuffle': True,
[36m(TaskRunner pid=2077808)[0m           'tokenizer': None,
[36m(TaskRunner pid=2077808)[0m           'train_batch_size': 64,
[36m(TaskRunner pid=2077808)[0m           'train_files': '/home/wangyc/verl/data/jec-qa-1-multi-choice/train.parquet',
[36m(TaskRunner pid=2077808)[0m           'truncation': 'error',
[36m(TaskRunner pid=2077808)[0m           'val_batch_size': 1312,
[36m(TaskRunner pid=2077808)[0m           'val_files': '/home/wangyc/verl/data/jec-qa-1-multi-choice/test.parquet',
[36m(TaskRunner pid=2077808)[0m           'video_key': 'videos'},
[36m(TaskRunner pid=2077808)[0m  'ray_init': {'num_cpus': None},
[36m(TaskRunner pid=2077808)[0m  'reward_model': {'enable': False,
[36m(TaskRunner pid=2077808)[0m                   'forward_max_token_len_per_gpu': 32768,
[36m(TaskRunner pid=2077808)[0m                   'max_length': None,
[36m(TaskRunner pid=2077808)[0m                   'micro_batch_size': None,
[36m(TaskRunner pid=2077808)[0m                   'micro_batch_size_per_gpu': None,
[36m(TaskRunner pid=2077808)[0m                   'model': {'external_lib': None,
[36m(TaskRunner pid=2077808)[0m                             'fsdp_config': {'fsdp_size': -1,
[36m(TaskRunner pid=2077808)[0m                                             'param_offload': False,
[36m(TaskRunner pid=2077808)[0m                                             'wrap_policy': {'min_num_params': 0}},
[36m(TaskRunner pid=2077808)[0m                             'input_tokenizer': '/home/wangyc/verl/Qwen/Qwen2___5-7B-Instruct',
[36m(TaskRunner pid=2077808)[0m                             'path': '~/models/FsfairX-LLaMA3-RM-v0.1',
[36m(TaskRunner pid=2077808)[0m                             'use_remove_padding': False},
[36m(TaskRunner pid=2077808)[0m                   'reward_manager': 'naive',
[36m(TaskRunner pid=2077808)[0m                   'strategy': 'fsdp',
[36m(TaskRunner pid=2077808)[0m                   'ulysses_sequence_parallel_size': 1,
[36m(TaskRunner pid=2077808)[0m                   'use_dynamic_bsz': False},
[36m(TaskRunner pid=2077808)[0m  'trainer': {'balance_batch': True,
[36m(TaskRunner pid=2077808)[0m              'critic_warmup': 0,
[36m(TaskRunner pid=2077808)[0m              'default_hdfs_dir': None,
[36m(TaskRunner pid=2077808)[0m              'default_local_dir': 'checkpoints/qwen2.5-7b-grpo-hard-mcq',
[36m(TaskRunner pid=2077808)[0m              'del_local_ckpt_after_load': False,
[36m(TaskRunner pid=2077808)[0m              'experiment_name': 'qwen2.5-7b-grpo-mcq',
[36m(TaskRunner pid=2077808)[0m              'log_val_generations': 0,
[36m(TaskRunner pid=2077808)[0m              'logger': ['console', 'wandb'],
[36m(TaskRunner pid=2077808)[0m              'max_actor_ckpt_to_keep': None,
[36m(TaskRunner pid=2077808)[0m              'max_critic_ckpt_to_keep': None,
[36m(TaskRunner pid=2077808)[0m              'n_gpus_per_node': 8,
[36m(TaskRunner pid=2077808)[0m              'nnodes': 1,
[36m(TaskRunner pid=2077808)[0m              'project_name': 'Lawyer-Zero',
[36m(TaskRunner pid=2077808)[0m              'ray_wait_register_center_timeout': 300,
[36m(TaskRunner pid=2077808)[0m              'resume_from_path': None,
[36m(TaskRunner pid=2077808)[0m              'resume_mode': 'auto',
[36m(TaskRunner pid=2077808)[0m              'save_freq': 50,
[36m(TaskRunner pid=2077808)[0m              'test_freq': 10,
[36m(TaskRunner pid=2077808)[0m              'total_epochs': 2,
[36m(TaskRunner pid=2077808)[0m              'total_training_steps': None,
[36m(TaskRunner pid=2077808)[0m              'val_before_train': True}}
[36m(TaskRunner pid=2077808)[0m WARNING: val_batch_size is deprecated. Validation datasets are sent to inference engines as a whole batch, which will schedule the memory themselves.
[36m(TaskRunner pid=2077808)[0m [validate_config] All configuration checks passed successfully!
[36m(TaskRunner pid=2077808)[0m dataset len: 8448
[36m(TaskRunner pid=2077808)[0m dataset len: 2113
[36m(TaskRunner pid=2077808)[0m Size of train dataloader: 132
[36m(TaskRunner pid=2077808)[0m Total training steps: 264
[36m(WorkerDict pid=2087560)[0m Loading checkpoint shards:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:11,  3.96s/it]
[36m(WorkerDict pid=2081628)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`[32m [repeated 7x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(WorkerDict pid=2081628)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.[32m [repeated 7x across cluster][0m
[36m(WorkerDict pid=2081628)[0m Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s][32m [repeated 7x across cluster][0m
[36m(WorkerDict pid=2081628)[0m Loading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:11<00:03,  3.75s/it][32m [repeated 16x across cluster][0m
[36m(WorkerDict pid=2081628)[0m Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:14<00:00,  3.57s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:14<00:00,  3.63s/it]
[36m(WorkerDict pid=2081628)[0m [rank0]:[W422 20:56:28.949676736 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[36m(WorkerDict pid=2081628)[0m Model config after override: Qwen2Config {
[36m(WorkerDict pid=2081628)[0m   "architectures": [
[36m(WorkerDict pid=2081628)[0m     "Qwen2ForCausalLM"
[36m(WorkerDict pid=2081628)[0m   ],
[36m(WorkerDict pid=2081628)[0m   "attention_dropout": 0.0,
[36m(WorkerDict pid=2081628)[0m   "eos_token_id": 151645,
[36m(WorkerDict pid=2081628)[0m   "hidden_act": "silu",
[36m(WorkerDict pid=2081628)[0m   "hidden_size": 3584,
[36m(WorkerDict pid=2081628)[0m   "initializer_range": 0.02,
[36m(WorkerDict pid=2081628)[0m   "intermediate_size": 18944,
[36m(WorkerDict pid=2081628)[0m   "max_position_embeddings": 32768,
[36m(WorkerDict pid=2081628)[0m   "max_window_layers": 28,
[36m(WorkerDict pid=2081628)[0m   "model_type": "qwen2",
[36m(WorkerDict pid=2081628)[0m   "num_attention_heads": 28,
[36m(WorkerDict pid=2081628)[0m   "num_hidden_layers": 28,
[36m(WorkerDict pid=2081628)[0m   "num_key_value_heads": 4,
[36m(WorkerDict pid=2081628)[0m   "pad_token_id": 151643,
[36m(WorkerDict pid=2081628)[0m   "rms_norm_eps": 1e-06,
[36m(WorkerDict pid=2081628)[0m   "rope_scaling": null,
[36m(WorkerDict pid=2081628)[0m   "rope_theta": 1000000.0,
[36m(WorkerDict pid=2081628)[0m   "sliding_window": 131072,
[36m(WorkerDict pid=2081628)[0m   "tie_word_embeddings": false,
[36m(WorkerDict pid=2081628)[0m   "torch_dtype": "bfloat16",
[36m(WorkerDict pid=2081628)[0m   "transformers_version": "4.51.3",
[36m(WorkerDict pid=2081628)[0m   "use_cache": true,
[36m(WorkerDict pid=2081628)[0m   "use_sliding_window": false,
[36m(WorkerDict pid=2081628)[0m   "vocab_size": 152064
[36m(WorkerDict pid=2081628)[0m }
[36m(WorkerDict pid=2081628)[0m 
[36m(WorkerDict pid=2081628)[0m Monkey patch _flash_attention_forward in transformers.integrations.flash_attention
[36m(WorkerDict pid=2081628)[0m NCCL version 2.21.5+cuda12.4
[36m(WorkerDict pid=2081628)[0m Qwen2ForCausalLM contains 7.62B parameters
[36m(WorkerDict pid=2081628)[0m wrap_policy: functools.partial(<function _or_policy at 0x7ef2a3f27be0>, policies=[functools.partial(<function transformer_auto_wrap_policy at 0x7ef2a3f27ac0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})])
[36m(WorkerDict pid=2087563)[0m Total steps: 264, num_warmup_steps: 0
[36m(WorkerDict pid=2087563)[0m Actor use_remove_padding=True
[36m(WorkerDict pid=2087550)[0m Monkey patch _flash_attention_forward in transformers.integrations.flash_attention[32m [repeated 7x across cluster][0m
[36m(WorkerDict pid=2087585)[0m wrap_policy: functools.partial(<function _or_policy at 0x7fbef8c33be0>, policies=[functools.partial(<function transformer_auto_wrap_policy at 0x7fbef8c33ac0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})])[32m [repeated 7x across cluster][0m
[36m(WorkerDict pid=2081628)[0m Before building vllm rollout, memory allocated (GB): 3.5703134536743164, memory reserved (GB): 11.697265625
[36m(WorkerDict pid=2087563)[0m WARNING 04-22 20:56:44 [cuda.py:96] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
[36m(WorkerDict pid=2081628)[0m Total steps: 264, num_warmup_steps: 0[32m [repeated 7x across cluster][0m
[36m(WorkerDict pid=2081628)[0m Actor use_remove_padding=True[32m [repeated 7x across cluster][0m
[36m(WorkerDict pid=2087572)[0m WARNING 04-22 20:56:45 [utils.py:2413] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7ee4cc36ace0>
[36m(WorkerDict pid=2087563)[0m NCCL version 2.21.5+cuda12.4
Error executing job with overrides: ['algorithm.adv_estimator=grpo', 'data.train_files=/home/wangyc/verl/data/jec-qa-1-multi-choice/train.parquet', 'data.val_files=/home/wangyc/verl/data/jec-qa-1-multi-choice/test.parquet', 'data.train_batch_size=64', 'data.val_batch_size=1312', 'data.max_prompt_length=1024', 'data.max_response_length=1024', 'actor_rollout_ref.model.path=/home/wangyc/verl/Qwen/Qwen2___5-7B-Instruct', 'actor_rollout_ref.actor.optim.lr=1e-6', 'actor_rollout_ref.model.use_remove_padding=True', 'actor_rollout_ref.actor.ppo_mini_batch_size=32', 'actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=16', 'actor_rollout_ref.actor.use_kl_loss=False', 'actor_rollout_ref.model.enable_gradient_checkpointing=True', 'actor_rollout_ref.actor.fsdp_config.param_offload=True', 'actor_rollout_ref.actor.fsdp_config.optimizer_offload=False', 'actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=32', 'actor_rollout_ref.rollout.tensor_model_parallel_size=2', 'actor_rollout_ref.rollout.name=vllm', 'actor_rollout_ref.rollout.gpu_memory_utilization=0.6', 'actor_rollout_ref.rollout.n=6', 'actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=32', 'actor_rollout_ref.ref.fsdp_config.param_offload=True', 'algorithm.kl_ctrl.kl_coef=0.0', 'trainer.critic_warmup=0', "trainer.logger=['console', 'wandb']", 'trainer.project_name=Lawyer-Zero', 'trainer.experiment_name=qwen2.5-7b-grpo-mcq', 'trainer.n_gpus_per_node=8', 'trainer.nnodes=1', 'trainer.default_local_dir=checkpoints/qwen2.5-7b-grpo-hard-mcq', 'trainer.save_freq=50', 'trainer.test_freq=10', 'trainer.total_epochs=2']
Traceback (most recent call last):
  File "/home/wangyc/verl/verl/trainer/main_ppo.py", line 63, in main
    run_ppo(config)
  File "/home/wangyc/verl/verl/trainer/main_ppo.py", line 80, in run_ppo
    ray.get(runner.run.remote(config))
  File "/home/wangyc/miniconda3/envs/verl/lib/python3.10/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/home/wangyc/miniconda3/envs/verl/lib/python3.10/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/home/wangyc/miniconda3/envs/verl/lib/python3.10/site-packages/ray/_private/worker.py", line 2771, in get
    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
  File "/home/wangyc/miniconda3/envs/verl/lib/python3.10/site-packages/ray/_private/worker.py", line 919, in get_objects
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(RuntimeError): [36mray::TaskRunner.run()[39m (pid=2077808, ip=222.29.51.203, actor_id=305c3c4a5928e5168a78bb0901000000, repr=<main_ppo.TaskRunner object at 0x7ecfff35f220>)
  File "/home/wangyc/verl/verl/trainer/main_ppo.py", line 207, in run
    trainer.init_workers()
  File "/home/wangyc/verl/verl/trainer/ppo/ray_trainer.py", line 734, in init_workers
    self.actor_rollout_wg.init_model()
  File "/home/wangyc/verl/verl/single_controller/ray/base.py", line 43, in func
    output = ray.get(output)
ray.exceptions.RayTaskError(RuntimeError): [36mray::WorkerDict.actor_rollout_init_model()[39m (pid=2087566, ip=222.29.51.203, actor_id=18608e9af2b22865bcfa79c901000000, repr=<verl.single_controller.ray.base.WorkerDict object at 0x7f3735bd2d10>)
  File "/home/wangyc/miniconda3/envs/verl/lib/python3.10/site-packages/vllm/model_executor/models/qwen2.py", line 480, in sample
    next_tokens = self.sampler(logits, sampling_metadata)
  File "/home/wangyc/miniconda3/envs/verl/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/wangyc/miniconda3/envs/verl/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/wangyc/miniconda3/envs/verl/lib/python3.10/site-packages/vllm/v1/sample/sampler.py", line 49, in forward
    sampled = self.sample(logits, sampling_metadata)
  File "/home/wangyc/miniconda3/envs/verl/lib/python3.10/site-packages/vllm/v1/sample/sampler.py", line 115, in sample
    random_sampled = self.topk_topp_sampler(
  File "/home/wangyc/miniconda3/envs/verl/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/wangyc/miniconda3/envs/verl/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/wangyc/miniconda3/envs/verl/lib/python3.10/site-packages/vllm/v1/sample/ops/topk_topp_sampler.py", line 98, in forward_native
    logits = apply_top_k_top_p(logits, k, p)
  File "/home/wangyc/miniconda3/envs/verl/lib/python3.10/site-packages/vllm/v1/sample/ops/topk_topp_sampler.py", line 186, in apply_top_k_top_p
    logits_sort, logits_idx = logits.sort(dim=-1, descending=False)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.74 GiB. GPU 0 has a total capacity of 44.53 GiB of which 1.71 GiB is free. Process 1443118 has 27.35 GiB memory in use. Including non-PyTorch memory, this process has 15.43 GiB memory in use. Of the allocated memory 14.63 GiB is allocated by PyTorch, with 103.41 MiB allocated in private pools (e.g., CUDA Graphs), and 6.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

The above exception was the direct cause of the following exception:

[36mray::WorkerDict.actor_rollout_init_model()[39m (pid=2087566, ip=222.29.51.203, actor_id=18608e9af2b22865bcfa79c901000000, repr=<verl.single_controller.ray.base.WorkerDict object at 0x7f3735bd2d10>)
  File "/home/wangyc/verl/verl/single_controller/ray/base.py", line 440, in func
    return getattr(self.worker_dict[key], name)(*args, **kwargs)
  File "/home/wangyc/verl/verl/single_controller/base/decorator.py", line 413, in inner
    return func(*args, **kwargs)
  File "/home/wangyc/verl/verl/workers/fsdp_workers.py", line 469, in init_model
    self.rollout, self.rollout_sharding_manager = self._build_rollout(
  File "/home/wangyc/verl/verl/workers/fsdp_workers.py", line 363, in _build_rollout
    rollout = vLLMRollout(
  File "/home/wangyc/verl/verl/workers/rollout/vllm_rollout/vllm_rollout_spmd.py", line 132, in __init__
    self.inference_engine = LLM(
  File "/home/wangyc/miniconda3/envs/verl/lib/python3.10/site-packages/vllm/utils.py", line 1096, in inner
    return fn(*args, **kwargs)
  File "/home/wangyc/miniconda3/envs/verl/lib/python3.10/site-packages/vllm/entrypoints/llm.py", line 243, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
  File "/home/wangyc/miniconda3/envs/verl/lib/python3.10/site-packages/vllm/engine/llm_engine.py", line 521, in from_engine_args
    return engine_cls.from_vllm_config(
  File "/home/wangyc/miniconda3/envs/verl/lib/python3.10/site-packages/vllm/v1/engine/llm_engine.py", line 115, in from_vllm_config
    return cls(vllm_config=vllm_config,
  File "/home/wangyc/miniconda3/envs/verl/lib/python3.10/site-packages/vllm/v1/engine/llm_engine.py", line 90, in __init__
    self.engine_core = EngineCoreClient.make_client(
  File "/home/wangyc/miniconda3/envs/verl/lib/python3.10/site-packages/vllm/v1/engine/core_client.py", line 74, in make_client
    return InprocClient(vllm_config, executor_class, log_stats)
  File "/home/wangyc/miniconda3/envs/verl/lib/python3.10/site-packages/vllm/v1/engine/core_client.py", line 197, in __init__
    self.engine_core = EngineCore(*args, **kwargs)
  File "/home/wangyc/miniconda3/envs/verl/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 71, in __init__
    self._initialize_kv_caches(vllm_config)
  File "/home/wangyc/miniconda3/envs/verl/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 132, in _initialize_kv_caches
    available_gpu_memory = self.model_executor.determine_available_memory()
  File "/home/wangyc/miniconda3/envs/verl/lib/python3.10/site-packages/vllm/v1/executor/abstract.py", line 98, in determine_available_memory
    memory = super().determine_available_memory()
  File "/home/wangyc/miniconda3/envs/verl/lib/python3.10/site-packages/vllm/v1/executor/abstract.py", line 66, in determine_available_memory
    output = self.collective_rpc("determine_available_memory")
  File "/home/wangyc/miniconda3/envs/verl/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 56, in collective_rpc
    answer = run_method(self.driver_worker, method, args, kwargs)
  File "/home/wangyc/miniconda3/envs/verl/lib/python3.10/site-packages/vllm/utils.py", line 2347, in run_method
    return func(*args, **kwargs)
  File "/home/wangyc/miniconda3/envs/verl/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/wangyc/miniconda3/envs/verl/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 157, in determine_available_memory
    self.model_runner.profile_run()
  File "/home/wangyc/miniconda3/envs/verl/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1575, in profile_run
    sampler_output = self._dummy_sampler_run(hidden_states)
  File "/home/wangyc/miniconda3/envs/verl/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/wangyc/miniconda3/envs/verl/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1470, in _dummy_sampler_run
    raise RuntimeError(
RuntimeError: CUDA out of memory occurred when warming up sampler with 1024 dummy requests. Please try lowering `max_num_seqs` or `gpu_memory_utilization` when initializing the engine.

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
[36m(WorkerDict pid=2087550)[0m Loading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:11<00:03,  3.96s/it][32m [repeated 7x across cluster][0m
[36m(WorkerDict pid=2087550)[0m Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:15<00:00,  3.84s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:15<00:00,  3.90s/it][32m [repeated 7x across cluster][0m
[36m(WorkerDict pid=2087550)[0m [rank1]:[W422 20:56:29.930205938 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.[32m [repeated 7x across cluster][0m
[36m(WorkerDict pid=2081628)[0m WARNING 04-22 20:56:46 [cuda.py:96] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used[32m [repeated 7x across cluster][0m
[36m(WorkerDict pid=2081628)[0m WARNING 04-22 20:56:47 [utils.py:2413] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7ef1b0190fd0>[32m [repeated 7x across cluster][0m
[36m(WorkerDict pid=2087555)[0m NCCL version 2.21.5+cuda12.4[32m [repeated 2x across cluster][0m
