2025-05-08 09:21:22,999	INFO worker.py:1832 -- Started a local Ray instance. View the dashboard at [1m[32m127.0.0.1:8266 [39m[22m
[36m(TaskRunner pid=1294262)[0m {'actor_rollout_ref': {'actor': {'checkpoint': {'contents': ['model',
[36m(TaskRunner pid=1294262)[0m                                                              'optimizer',
[36m(TaskRunner pid=1294262)[0m                                                              'extra']},
[36m(TaskRunner pid=1294262)[0m                                  'clip_ratio': 0.2,
[36m(TaskRunner pid=1294262)[0m                                  'clip_ratio_c': 3.0,
[36m(TaskRunner pid=1294262)[0m                                  'clip_ratio_high': 0.2,
[36m(TaskRunner pid=1294262)[0m                                  'clip_ratio_low': 0.2,
[36m(TaskRunner pid=1294262)[0m                                  'entropy_coeff': 0,
[36m(TaskRunner pid=1294262)[0m                                  'fsdp_config': {'fsdp_size': -1,
[36m(TaskRunner pid=1294262)[0m                                                  'optimizer_offload': False,
[36m(TaskRunner pid=1294262)[0m                                                  'param_offload': False,
[36m(TaskRunner pid=1294262)[0m                                                  'wrap_policy': {'min_num_params': 0}},
[36m(TaskRunner pid=1294262)[0m                                  'grad_clip': 1.0,
[36m(TaskRunner pid=1294262)[0m                                  'kl_loss_coef': 0.001,
[36m(TaskRunner pid=1294262)[0m                                  'kl_loss_type': 'low_var_kl',
[36m(TaskRunner pid=1294262)[0m                                  'loss_agg_mode': 'seq-mean-token-sum-norm',
[36m(TaskRunner pid=1294262)[0m                                  'optim': {'lr': 1e-06,
[36m(TaskRunner pid=1294262)[0m                                            'lr_warmup_steps': -1,
[36m(TaskRunner pid=1294262)[0m                                            'lr_warmup_steps_ratio': 0.0,
[36m(TaskRunner pid=1294262)[0m                                            'min_lr_ratio': None,
[36m(TaskRunner pid=1294262)[0m                                            'total_training_steps': -1,
[36m(TaskRunner pid=1294262)[0m                                            'warmup_style': 'constant',
[36m(TaskRunner pid=1294262)[0m                                            'weight_decay': 0.01},
[36m(TaskRunner pid=1294262)[0m                                  'ppo_epochs': 1,
[36m(TaskRunner pid=1294262)[0m                                  'ppo_max_token_len_per_gpu': 16384,
[36m(TaskRunner pid=1294262)[0m                                  'ppo_micro_batch_size': None,
[36m(TaskRunner pid=1294262)[0m                                  'ppo_micro_batch_size_per_gpu': 32,
[36m(TaskRunner pid=1294262)[0m                                  'ppo_mini_batch_size': 128,
[36m(TaskRunner pid=1294262)[0m                                  'shuffle': False,
[36m(TaskRunner pid=1294262)[0m                                  'strategy': 'fsdp',
[36m(TaskRunner pid=1294262)[0m                                  'ulysses_sequence_parallel_size': 1,
[36m(TaskRunner pid=1294262)[0m                                  'use_dynamic_bsz': False,
[36m(TaskRunner pid=1294262)[0m                                  'use_kl_loss': True,
[36m(TaskRunner pid=1294262)[0m                                  'use_torch_compile': True},
[36m(TaskRunner pid=1294262)[0m                        'hybrid_engine': True,
[36m(TaskRunner pid=1294262)[0m                        'model': {'enable_gradient_checkpointing': True,
[36m(TaskRunner pid=1294262)[0m                                  'external_lib': None,
[36m(TaskRunner pid=1294262)[0m                                  'override_config': {},
[36m(TaskRunner pid=1294262)[0m                                  'path': '/home/wangyc/verl/Qwen/Qwen2.5-7B-Instruct',
[36m(TaskRunner pid=1294262)[0m                                  'use_liger': False,
[36m(TaskRunner pid=1294262)[0m                                  'use_remove_padding': True},
[36m(TaskRunner pid=1294262)[0m                        'ref': {'fsdp_config': {'param_offload': True,
[36m(TaskRunner pid=1294262)[0m                                                'wrap_policy': {'min_num_params': 0}},
[36m(TaskRunner pid=1294262)[0m                                'log_prob_max_token_len_per_gpu': 16384,
[36m(TaskRunner pid=1294262)[0m                                'log_prob_micro_batch_size': None,
[36m(TaskRunner pid=1294262)[0m                                'log_prob_micro_batch_size_per_gpu': 32,
[36m(TaskRunner pid=1294262)[0m                                'log_prob_use_dynamic_bsz': False,
[36m(TaskRunner pid=1294262)[0m                                'strategy': 'fsdp',
[36m(TaskRunner pid=1294262)[0m                                'ulysses_sequence_parallel_size': 1},
[36m(TaskRunner pid=1294262)[0m                        'rollout': {'disable_log_stats': True,
[36m(TaskRunner pid=1294262)[0m                                    'do_sample': True,
[36m(TaskRunner pid=1294262)[0m                                    'dtype': 'bfloat16',
[36m(TaskRunner pid=1294262)[0m                                    'enable_chunked_prefill': True,
[36m(TaskRunner pid=1294262)[0m                                    'enforce_eager': True,
[36m(TaskRunner pid=1294262)[0m                                    'engine_kwargs': {'swap_space': None},
[36m(TaskRunner pid=1294262)[0m                                    'free_cache_engine': True,
[36m(TaskRunner pid=1294262)[0m                                    'gpu_memory_utilization': 0.6,
[36m(TaskRunner pid=1294262)[0m                                    'ignore_eos': False,
[36m(TaskRunner pid=1294262)[0m                                    'load_format': 'dummy_dtensor',
[36m(TaskRunner pid=1294262)[0m                                    'log_prob_max_token_len_per_gpu': 16384,
[36m(TaskRunner pid=1294262)[0m                                    'log_prob_micro_batch_size': None,
[36m(TaskRunner pid=1294262)[0m                                    'log_prob_micro_batch_size_per_gpu': 32,
[36m(TaskRunner pid=1294262)[0m                                    'log_prob_use_dynamic_bsz': False,
[36m(TaskRunner pid=1294262)[0m                                    'max_model_len': None,
[36m(TaskRunner pid=1294262)[0m                                    'max_num_batched_tokens': 8192,
[36m(TaskRunner pid=1294262)[0m                                    'max_num_seqs': 1024,
[36m(TaskRunner pid=1294262)[0m                                    'n': 6,
[36m(TaskRunner pid=1294262)[0m                                    'name': 'vllm',
[36m(TaskRunner pid=1294262)[0m                                    'prompt_length': 1024,
[36m(TaskRunner pid=1294262)[0m                                    'response_length': 1024,
[36m(TaskRunner pid=1294262)[0m                                    'temperature': 1.0,
[36m(TaskRunner pid=1294262)[0m                                    'tensor_model_parallel_size': 2,
[36m(TaskRunner pid=1294262)[0m                                    'top_k': -1,
[36m(TaskRunner pid=1294262)[0m                                    'top_p': 1,
[36m(TaskRunner pid=1294262)[0m                                    'use_fire_sampling': False,
[36m(TaskRunner pid=1294262)[0m                                    'val_kwargs': {'do_sample': False,
[36m(TaskRunner pid=1294262)[0m                                                   'n': 1,
[36m(TaskRunner pid=1294262)[0m                                                   'temperature': 0,
[36m(TaskRunner pid=1294262)[0m                                                   'top_k': -1,
[36m(TaskRunner pid=1294262)[0m                                                   'top_p': 1.0}}},
[36m(TaskRunner pid=1294262)[0m  'algorithm': {'adv_estimator': 'grpo',
[36m(TaskRunner pid=1294262)[0m                'gamma': 1.0,
[36m(TaskRunner pid=1294262)[0m                'kl_ctrl': {'horizon': 10000,
[36m(TaskRunner pid=1294262)[0m                            'kl_coef': 0.001,
[36m(TaskRunner pid=1294262)[0m                            'target_kl': 0.1,
[36m(TaskRunner pid=1294262)[0m DeprecationWarning: `ray.state.available_resources_per_node` is a private attribute and access will be removed in a future Ray version.
[36m(TaskRunner pid=1294262)[0m WARNING:2025-05-08 09:21:38,948:Waiting for register center actor mhyfic_register_center to be ready. Elapsed time: 0 seconds out of 300 seconds.
[36m(TaskRunner pid=1294262)[0m                            'type': 'fixed'},
[36m(TaskRunner pid=1294262)[0m                'kl_penalty': 'kl',
[36m(TaskRunner pid=1294262)[0m                'lam': 1.0,
[36m(TaskRunner pid=1294262)[0m                'norm_adv_by_std_in_grpo': False,
[36m(TaskRunner pid=1294262)[0m                'use_kl_in_reward': False},
[36m(TaskRunner pid=1294262)[0m  'critic': {'checkpoint': {'contents': ['model', 'optimizer', 'extra']},
[36m(TaskRunner pid=1294262)[0m             'cliprange_value': 0.5,
[36m(TaskRunner pid=1294262)[0m             'forward_max_token_len_per_gpu': 32768,
[36m(TaskRunner pid=1294262)[0m             'forward_micro_batch_size': None,
[36m(TaskRunner pid=1294262)[0m             'forward_micro_batch_size_per_gpu': None,
[36m(TaskRunner pid=1294262)[0m             'grad_clip': 1.0,
[36m(TaskRunner pid=1294262)[0m             'model': {'enable_gradient_checkpointing': True,
[36m(TaskRunner pid=1294262)[0m                       'external_lib': None,
[36m(TaskRunner pid=1294262)[0m                       'fsdp_config': {'fsdp_size': -1,
[36m(TaskRunner pid=1294262)[0m                                       'optimizer_offload': False,
[36m(TaskRunner pid=1294262)[0m                                       'param_offload': False,
[36m(TaskRunner pid=1294262)[0m                                       'wrap_policy': {'min_num_params': 0}},
[36m(TaskRunner pid=1294262)[0m                       'override_config': {},
[36m(TaskRunner pid=1294262)[0m                       'path': '~/models/deepseek-llm-7b-chat',
[36m(TaskRunner pid=1294262)[0m                       'tokenizer_path': '/home/wangyc/verl/Qwen/Qwen2.5-7B-Instruct',
[36m(TaskRunner pid=1294262)[0m                       'use_remove_padding': False},
[36m(TaskRunner pid=1294262)[0m             'optim': {'lr': 1e-05,
[36m(TaskRunner pid=1294262)[0m                       'lr_warmup_steps_ratio': 0.0,
[36m(TaskRunner pid=1294262)[0m                       'min_lr_ratio': None,
[36m(TaskRunner pid=1294262)[0m                       'total_training_steps': -1,
[36m(TaskRunner pid=1294262)[0m                       'warmup_style': 'constant',
[36m(TaskRunner pid=1294262)[0m                       'weight_decay': 0.01},
[36m(TaskRunner pid=1294262)[0m             'ppo_epochs': 1,
[36m(TaskRunner pid=1294262)[0m             'ppo_max_token_len_per_gpu': 32768,
[36m(TaskRunner pid=1294262)[0m             'ppo_micro_batch_size': None,
[36m(TaskRunner pid=1294262)[0m             'ppo_micro_batch_size_per_gpu': None,
[36m(TaskRunner pid=1294262)[0m             'ppo_mini_batch_size': 128,
[36m(TaskRunner pid=1294262)[0m             'rollout_n': 6,
[36m(TaskRunner pid=1294262)[0m             'shuffle': False,
[36m(TaskRunner pid=1294262)[0m             'strategy': 'fsdp',
[36m(TaskRunner pid=1294262)[0m             'ulysses_sequence_parallel_size': 1,
[36m(TaskRunner pid=1294262)[0m             'use_dynamic_bsz': False},
[36m(TaskRunner pid=1294262)[0m  'custom_reward_function': {'name': 'compute_score', 'path': None},
[36m(TaskRunner pid=1294262)[0m  'data': {'custom_cls': {'name': None, 'path': None},
[36m(TaskRunner pid=1294262)[0m           'filter_overlong_prompts': False,
[36m(TaskRunner pid=1294262)[0m           'filter_overlong_prompts_workers': 1,
[36m(TaskRunner pid=1294262)[0m           'image_key': 'images',
[36m(TaskRunner pid=1294262)[0m           'max_prompt_length': 1024,
[36m(TaskRunner pid=1294262)[0m           'max_response_length': 1024,
[36m(TaskRunner pid=1294262)[0m           'prompt_key': 'prompt',
[36m(TaskRunner pid=1294262)[0m           'return_raw_chat': False,
[36m(TaskRunner pid=1294262)[0m           'return_raw_input_ids': False,
[36m(TaskRunner pid=1294262)[0m           'reward_fn_key': 'data_source',
[36m(TaskRunner pid=1294262)[0m           'shuffle': True,
[36m(TaskRunner pid=1294262)[0m           'tokenizer': None,
[36m(TaskRunner pid=1294262)[0m           'train_batch_size': 128,
[36m(TaskRunner pid=1294262)[0m           'train_files': '/home/wangyc/verl/data/jec-qa-1-multi-choice/train.parquet',
[36m(TaskRunner pid=1294262)[0m           'truncation': 'error',
[36m(TaskRunner pid=1294262)[0m           'val_batch_size': 1312,
[36m(TaskRunner pid=1294262)[0m           'val_files': '/home/wangyc/verl/data/jec-qa-1-multi-choice/test.parquet',
[36m(TaskRunner pid=1294262)[0m           'video_key': 'videos'},
[36m(TaskRunner pid=1294262)[0m  'ray_init': {'num_cpus': None},
[36m(TaskRunner pid=1294262)[0m  'reward_model': {'enable': False,
[36m(TaskRunner pid=1294262)[0m                   'forward_max_token_len_per_gpu': 32768,
[36m(TaskRunner pid=1294262)[0m                   'max_length': None,
[36m(TaskRunner pid=1294262)[0m                   'micro_batch_size': None,
[36m(TaskRunner pid=1294262)[0m                   'micro_batch_size_per_gpu': None,
[36m(TaskRunner pid=1294262)[0m                   'model': {'external_lib': None,
[36m(TaskRunner pid=1294262)[0m                             'fsdp_config': {'fsdp_size': -1,
[36m(TaskRunner pid=1294262)[0m                                             'param_offload': False,
[36m(TaskRunner pid=1294262)[0m                                             'wrap_policy': {'min_num_params': 0}},
[36m(TaskRunner pid=1294262)[0m                             'input_tokenizer': '/home/wangyc/verl/Qwen/Qwen2.5-7B-Instruct',
[36m(TaskRunner pid=1294262)[0m                             'path': '~/models/FsfairX-LLaMA3-RM-v0.1',
[36m(TaskRunner pid=1294262)[0m                             'use_remove_padding': False},
[36m(TaskRunner pid=1294262)[0m                   'reward_manager': 'naive',
[36m(TaskRunner pid=1294262)[0m                   'strategy': 'fsdp',
[36m(TaskRunner pid=1294262)[0m                   'ulysses_sequence_parallel_size': 1,
[36m(TaskRunner pid=1294262)[0m                   'use_dynamic_bsz': False},
[36m(TaskRunner pid=1294262)[0m  'trainer': {'balance_batch': True,
[36m(TaskRunner pid=1294262)[0m              'critic_warmup': 0,
[36m(TaskRunner pid=1294262)[0m              'default_hdfs_dir': None,
[36m(TaskRunner pid=1294262)[0m              'default_local_dir': 'checkpoints/qwen2.5-7b-grpo-hard-mcq',
[36m(TaskRunner pid=1294262)[0m              'del_local_ckpt_after_load': False,
[36m(TaskRunner pid=1294262)[0m              'experiment_name': 'qwen2.5-7b-grpo-mcq',
[36m(TaskRunner pid=1294262)[0m              'log_val_generations': 0,
[36m(TaskRunner pid=1294262)[0m              'logger': ['console'],
[36m(TaskRunner pid=1294262)[0m              'max_actor_ckpt_to_keep': None,
[36m(TaskRunner pid=1294262)[0m              'max_critic_ckpt_to_keep': None,
[36m(TaskRunner pid=1294262)[0m              'n_gpus_per_node': 8,
[36m(TaskRunner pid=1294262)[0m              'nnodes': 1,
[36m(TaskRunner pid=1294262)[0m              'project_name': 'Lawyer-Zero',
[36m(TaskRunner pid=1294262)[0m              'ray_wait_register_center_timeout': 300,
[36m(TaskRunner pid=1294262)[0m              'resume_from_path': None,
[36m(TaskRunner pid=1294262)[0m              'resume_mode': 'auto',
[36m(TaskRunner pid=1294262)[0m              'save_freq': 50,
[36m(TaskRunner pid=1294262)[0m              'test_freq': 10,
[36m(TaskRunner pid=1294262)[0m              'total_epochs': 2,
[36m(TaskRunner pid=1294262)[0m              'total_training_steps': None,
[36m(TaskRunner pid=1294262)[0m              'val_before_train': True}}
[36m(TaskRunner pid=1294262)[0m WARNING: val_batch_size is deprecated. Validation datasets are sent to inference engines as a whole batch, which will schedule the memory themselves.
[36m(TaskRunner pid=1294262)[0m [validate_config] All configuration checks passed successfully!
[36m(TaskRunner pid=1294262)[0m dataset len: 8448
[36m(TaskRunner pid=1294262)[0m dataset len: 2113
[36m(TaskRunner pid=1294262)[0m Size of train dataloader: 66
[36m(TaskRunner pid=1294262)[0m Total training steps: 132
[36m(WorkerDict pid=1302891)[0m Model config after override: Qwen2Config {
[36m(WorkerDict pid=1302891)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[36m(WorkerDict pid=1302891)[0m Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[36m(WorkerDict pid=1302891)[0m Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:02,  1.29it/s]
[36m(WorkerDict pid=1302891)[0m Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.30it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.22it/s]
[36m(WorkerDict pid=1302891)[0m [rank0]:[W508 09:22:00.650669540 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[36m(WorkerDict pid=1302891)[0m   "architectures": [
[36m(WorkerDict pid=1302891)[0m     "Qwen2ForCausalLM"
[36m(WorkerDict pid=1302891)[0m   ],
[36m(WorkerDict pid=1302891)[0m   "attention_dropout": 0.0,
[36m(WorkerDict pid=1302891)[0m   "eos_token_id": 151645,
[36m(WorkerDict pid=1302891)[0m   "hidden_act": "silu",
[36m(WorkerDict pid=1302891)[0m   "hidden_size": 3584,
[36m(WorkerDict pid=1302891)[0m   "initializer_range": 0.02,
[36m(WorkerDict pid=1302891)[0m   "intermediate_size": 18944,
[36m(WorkerDict pid=1302891)[0m   "max_position_embeddings": 32768,
[36m(WorkerDict pid=1302891)[0m   "max_window_layers": 28,
[36m(WorkerDict pid=1302891)[0m   "model_type": "qwen2",
[36m(WorkerDict pid=1302891)[0m   "num_attention_heads": 28,
[36m(WorkerDict pid=1302891)[0m   "num_hidden_layers": 28,
[36m(WorkerDict pid=1302891)[0m   "num_key_value_heads": 4,
[36m(WorkerDict pid=1302891)[0m   "pad_token_id": 151643,
[36m(WorkerDict pid=1302891)[0m   "rms_norm_eps": 1e-06,
[36m(WorkerDict pid=1302891)[0m   "rope_scaling": null,
[36m(WorkerDict pid=1302891)[0m   "rope_theta": 1000000.0,
[36m(WorkerDict pid=1302891)[0m   "sliding_window": 131072,
[36m(WorkerDict pid=1302891)[0m   "tie_word_embeddings": false,
[36m(WorkerDict pid=1302891)[0m   "torch_dtype": "bfloat16",
[36m(WorkerDict pid=1302891)[0m   "transformers_version": "4.51.3",
[36m(WorkerDict pid=1302891)[0m   "use_cache": true,
[36m(WorkerDict pid=1302891)[0m   "use_sliding_window": false,
[36m(WorkerDict pid=1302891)[0m   "vocab_size": 152064
[36m(WorkerDict pid=1302891)[0m }
[36m(WorkerDict pid=1302891)[0m 
[36m(WorkerDict pid=1302891)[0m Monkey patch _flash_attention_forward in transformers.integrations.flash_attention
[36m(WorkerDict pid=1302891)[0m NCCL version 2.21.5+cuda12.4
[36m(WorkerDict pid=1302891)[0m Qwen2ForCausalLM contains 7.62B parameters
[36m(WorkerDict pid=1302891)[0m wrap_policy: functools.partial(<function _or_policy at 0x7ee1f903a8c0>, policies=[functools.partial(<function transformer_auto_wrap_policy at 0x7ee1f903a7a0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})])
Error executing job with overrides: ['algorithm.adv_estimator=grpo', 'data.train_files=/home/wangyc/verl/data/jec-qa-1-multi-choice/train.parquet', 'data.val_files=/home/wangyc/verl/data/jec-qa-1-multi-choice/test.parquet', 'data.train_batch_size=128', 'data.val_batch_size=1312', 'data.max_prompt_length=1024', 'data.max_response_length=1024', 'actor_rollout_ref.model.path=/home/wangyc/verl/Qwen/Qwen2.5-7B-Instruct', 'actor_rollout_ref.actor.optim.lr=1e-6', 'actor_rollout_ref.model.use_remove_padding=True', 'actor_rollout_ref.actor.ppo_mini_batch_size=128', 'actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=32', 'actor_rollout_ref.actor.loss_agg_mode=seq-mean-token-sum-norm', 'actor_rollout_ref.actor.use_kl_loss=True', 'actor_rollout_ref.actor.kl_loss_coef=0.001', 'actor_rollout_ref.actor.kl_loss_type=low_var_kl', 'actor_rollout_ref.actor.entropy_coeff=0', 'actor_rollout_ref.model.enable_gradient_checkpointing=True', 'actor_rollout_ref.actor.fsdp_config.param_offload=False', 'actor_rollout_ref.actor.fsdp_config.optimizer_offload=False', 'actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=32', 'actor_rollout_ref.rollout.tensor_model_parallel_size=2', 'actor_rollout_ref.rollout.name=vllm', 'actor_rollout_ref.rollout.gpu_memory_utilization=0.6', 'actor_rollout_ref.rollout.n=6', 'actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=32', 'actor_rollout_ref.ref.fsdp_config.param_offload=True', 'algorithm.use_kl_in_reward=False', 'algorithm.norm_adv_by_std_in_grpo=False', 'trainer.critic_warmup=0', "trainer.logger=['console']", 'trainer.project_name=Lawyer-Zero', 'trainer.experiment_name=qwen2.5-7b-grpo-mcq', 'trainer.n_gpus_per_node=8', 'trainer.nnodes=1', 'trainer.default_local_dir=checkpoints/qwen2.5-7b-grpo-hard-mcq', 'trainer.save_freq=50', 'trainer.test_freq=10', 'trainer.total_epochs=2']
[36m(TaskRunner pid=1294262)[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): [36mray::WorkerDict.ref_init_model()[39m (pid=1305111, ip=222.29.51.203, actor_id=3fae3916f833ee534832011d01000000, repr=<verl.single_controller.ray.base.WorkerDict object at 0x7f10abc08220>)
[36m(TaskRunner pid=1294262)[0m   File "/home/wangyc/verl/verl/single_controller/ray/base.py", line 440, in func
[36m(TaskRunner pid=1294262)[0m     return getattr(self.worker_dict[key], name)(*args, **kwargs)
[36m(TaskRunner pid=1294262)[0m   File "/home/wangyc/verl/verl/single_controller/base/decorator.py", line 413, in inner
[36m(TaskRunner pid=1294262)[0m     return func(*args, **kwargs)
[36m(TaskRunner pid=1294262)[0m   File "/home/wangyc/verl/verl/workers/fsdp_workers.py", line 474, in init_model
[36m(TaskRunner pid=1294262)[0m     self.ref_module_fsdp = self._build_model_optimizer(
[36m(TaskRunner pid=1294262)[0m   File "/home/wangyc/verl/verl/workers/fsdp_workers.py", line 276, in _build_model_optimizer
[36m(TaskRunner pid=1294262)[0m     actor_module_fsdp = FSDP(
[36m(TaskRunner pid=1294262)[0m   File "/home/wangyc/miniconda3/envs/verl/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 509, in __init__
[36m(TaskRunner pid=1294262)[0m     _init_param_handle_from_module(
[36m(TaskRunner pid=1294262)[0m   File "/home/wangyc/miniconda3/envs/verl/lib/python3.10/site-packages/torch/distributed/fsdp/_init_utils.py", line 589, in _init_param_handle_from_module
[36m(TaskRunner pid=1294262)[0m     _materialize_with_param_init_fn(
[36m(TaskRunner pid=1294262)[0m   File "/home/wangyc/miniconda3/envs/verl/lib/python3.10/site-packages/torch/distributed/fsdp/_init_utils.py", line 898, in _materialize_with_param_init_fn
[36m(TaskRunner pid=1294262)[0m     param_init_fn(module)
[36m(TaskRunner pid=1294262)[0m   File "/home/wangyc/verl/verl/utils/fsdp_utils.py", line 35, in init_fn
[36m(TaskRunner pid=1294262)[0m     x = x.to_empty(device=torch.cuda.current_device(), recurse=False)
[36m(TaskRunner pid=1294262)[0m   File "/home/wangyc/miniconda3/envs/verl/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1195, in to_empty
[36m(TaskRunner pid=1294262)[0m     return self._apply(
[36m(TaskRunner pid=1294262)[0m   File "/home/wangyc/miniconda3/envs/verl/lib/python3.10/site-packages/torch/nn/modules/module.py", line 930, in _apply
[36m(TaskRunner pid=1294262)[0m     param_applied = fn(param)
[36m(TaskRunner pid=1294262)[0m   File "/home/wangyc/miniconda3/envs/verl/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1196, in <lambda>
[36m(TaskRunner pid=1294262)[0m     lambda t: torch.empty_like(t, device=device), recurse=recurse
[36m(TaskRunner pid=1294262)[0m   File "/home/wangyc/miniconda3/envs/verl/lib/python3.10/site-packages/torch/_prims_common/wrappers.py", line 291, in _fn
[36m(TaskRunner pid=1294262)[0m     result = fn(*args, **kwargs)
[36m(TaskRunner pid=1294262)[0m   File "/home/wangyc/miniconda3/envs/verl/lib/python3.10/site-packages/torch/_refs/__init__.py", line 5003, in empty_like
[36m(TaskRunner pid=1294262)[0m     return torch.empty_permuted(
[36m(TaskRunner pid=1294262)[0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 44.53 GiB of which 499.50 MiB is free. Process 552232 has 42.32 GiB memory in use. Including non-PyTorch memory, this process has 1.68 GiB memory in use. Of the allocated memory 1.02 GiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[36m(TaskRunner pid=1294262)[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): [36mray::WorkerDict.ref_init_model()[39m (pid=1305125, ip=222.29.51.203, actor_id=024fe10e1f990770c098d57801000000, repr=<verl.single_controller.ray.base.WorkerDict object at 0x7f7b68830220>)
[36m(TaskRunner pid=1294262)[0m   File "/home/wangyc/verl/verl/single_controller/ray/base.py", line 440, in func
[36m(TaskRunner pid=1294262)[0m     return getattr(self.worker_dict[key], name)(*args, **kwargs)
[36m(TaskRunner pid=1294262)[0m   File "/home/wangyc/verl/verl/single_controller/base/decorator.py", line 413, in inner
[36m(TaskRunner pid=1294262)[0m     return func(*args, **kwargs)
[36m(TaskRunner pid=1294262)[0m   File "/home/wangyc/verl/verl/workers/fsdp_workers.py", line 474, in init_model
[36m(TaskRunner pid=1294262)[0m     self.ref_module_fsdp = self._build_model_optimizer(
[36m(TaskRunner pid=1294262)[0m   File "/home/wangyc/verl/verl/workers/fsdp_workers.py", line 276, in _build_model_optimizer
[36m(TaskRunner pid=1294262)[0m     actor_module_fsdp = FSDP(
[36m(TaskRunner pid=1294262)[0m   File "/home/wangyc/miniconda3/envs/verl/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 509, in __init__
[36m(TaskRunner pid=1294262)[0m     _init_param_handle_from_module(
[36m(TaskRunner pid=1294262)[0m   File "/home/wangyc/miniconda3/envs/verl/lib/python3.10/site-packages/torch/distributed/fsdp/_init_utils.py", line 589, in _init_param_handle_from_module
[36m(TaskRunner pid=1294262)[0m     _materialize_with_param_init_fn(
[36m(TaskRunner pid=1294262)[0m   File "/home/wangyc/miniconda3/envs/verl/lib/python3.10/site-packages/torch/distributed/fsdp/_init_utils.py", line 898, in _materialize_with_param_init_fn
[36m(TaskRunner pid=1294262)[0m     param_init_fn(module)
[36m(TaskRunner pid=1294262)[0m   File "/home/wangyc/verl/verl/utils/fsdp_utils.py", line 35, in init_fn
[36m(TaskRunner pid=1294262)[0m     x = x.to_empty(device=torch.cuda.current_device(), recurse=False)
[36m(TaskRunner pid=1294262)[0m   File "/home/wangyc/miniconda3/envs/verl/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1195, in to_empty
Traceback (most recent call last):
[36m(TaskRunner pid=1294262)[0m     return self._apply(
  File "/home/wangyc/verl/verl/trainer/main_ppo.py", line 63, in main
    run_ppo(config)
[36m(TaskRunner pid=1294262)[0m   File "/home/wangyc/miniconda3/envs/verl/lib/python3.10/site-packages/torch/nn/modules/module.py", line 930, in _apply
  File "/home/wangyc/verl/verl/trainer/main_ppo.py", line 80, in run_ppo
    ray.get(runner.run.remote(config))
[36m(TaskRunner pid=1294262)[0m     param_applied = fn(param)
  File "/home/wangyc/miniconda3/envs/verl/lib/python3.10/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
    return fn(*args, **kwargs)
[36m(TaskRunner pid=1294262)[0m   File "/home/wangyc/miniconda3/envs/verl/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1196, in <lambda>
  File "/home/wangyc/miniconda3/envs/verl/lib/python3.10/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
[36m(TaskRunner pid=1294262)[0m     lambda t: torch.empty_like(t, device=device), recurse=recurse
  File "/home/wangyc/miniconda3/envs/verl/lib/python3.10/site-packages/ray/_private/worker.py", line 2771, in get
    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(TaskRunner pid=1294262)[0m   File "/home/wangyc/miniconda3/envs/verl/lib/python3.10/site-packages/torch/_prims_common/wrappers.py", line 291, in _fn
  File "/home/wangyc/miniconda3/envs/verl/lib/python3.10/site-packages/ray/_private/worker.py", line 919, in get_objects
    raise value.as_instanceof_cause()
[36m(TaskRunner pid=1294262)[0m     result = fn(*args, **kwargs)
ray.exceptions.RayTaskError(OutOfMemoryError): [36mray::TaskRunner.run()[39m (pid=1294262, ip=222.29.51.203, actor_id=11c46f7ad440c00b9b6b2e5f01000000, repr=<main_ppo.TaskRunner object at 0x7f024e26f0a0>)
  File "/home/wangyc/verl/verl/trainer/main_ppo.py", line 207, in run
    trainer.init_workers()
  File "/home/wangyc/verl/verl/trainer/ppo/ray_trainer.py", line 726, in init_workers
    self.ref_policy_wg.init_model()
  File "/home/wangyc/verl/verl/single_controller/ray/base.py", line 43, in func
    output = ray.get(output)
ray.exceptions.RayTaskError(OutOfMemoryError): [36mray::WorkerDict.ref_init_model()[39m (pid=1305128, ip=222.29.51.203, actor_id=a1f7aed11ba97b4906a5788101000000, repr=<verl.single_controller.ray.base.WorkerDict object at 0x7ed2b9d78250>)
  File "/home/wangyc/verl/verl/single_controller/ray/base.py", line 440, in func
    return getattr(self.worker_dict[key], name)(*args, **kwargs)
  File "/home/wangyc/verl/verl/single_controller/base/decorator.py", line 413, in inner
    return func(*args, **kwargs)
  File "/home/wangyc/verl/verl/workers/fsdp_workers.py", line 474, in init_model
    self.ref_module_fsdp = self._build_model_optimizer(
  File "/home/wangyc/verl/verl/workers/fsdp_workers.py", line 276, in _build_model_optimizer
    actor_module_fsdp = FSDP(
  File "/home/wangyc/miniconda3/envs/verl/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 509, in __init__
    _init_param_handle_from_module(
  File "/home/wangyc/miniconda3/envs/verl/lib/python3.10/site-packages/torch/distributed/fsdp/_init_utils.py", line 629, in _init_param_handle_from_module
    _sync_module_params_and_buffers(
  File "/home/wangyc/miniconda3/envs/verl/lib/python3.10/site-packages/torch/distributed/fsdp/_init_utils.py", line 1126, in _sync_module_params_and_buffers
    _sync_params_and_buffers(
  File "/home/wangyc/miniconda3/envs/verl/lib/python3.10/site-packages/torch/distributed/utils.py", line 334, in _sync_params_and_buffers
    dist._broadcast_coalesced(
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 44.53 GiB of which 569.50 MiB is free. Process 552249 has 41.26 GiB memory in use. Including non-PyTorch memory, this process has 2.67 GiB memory in use. Of the allocated memory 2.03 GiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[36m(TaskRunner pid=1294262)[0m   File "/home/wangyc/miniconda3/envs/verl/lib/python3.10/site-packages/torch/_refs/__init__.py", line 5003, in empty_like

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
[36m(TaskRunner pid=1294262)[0m     return torch.empty_permuted(
[36m(TaskRunner pid=1294262)[0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 44.53 GiB of which 619.50 MiB is free. Process 552246 has 42.23 GiB memory in use. Including non-PyTorch memory, this process has 1.66 GiB memory in use. Of the allocated memory 1.02 GiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[36m(WorkerDict pid=1305125)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.[32m [repeated 7x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(WorkerDict pid=1305125)[0m Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s][32m [repeated 7x across cluster][0m
[36m(WorkerDict pid=1302891)[0m Loading checkpoint shards:  75%|███████▌  | 3/4 [00:02<00:00,  1.08it/s][32m [repeated 23x across cluster][0m
[36m(WorkerDict pid=1305125)[0m Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.30it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.21it/s][32m [repeated 7x across cluster][0m
[36m(WorkerDict pid=1305125)[0m [rank3]:[W508 09:21:59.635797291 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 3]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.[32m [repeated 7x across cluster][0m
[36m(WorkerDict pid=1305134)[0m Monkey patch _flash_attention_forward in transformers.integrations.flash_attention[32m [repeated 7x across cluster][0m
[36m(WorkerDict pid=1305134)[0m wrap_policy: functools.partial(<function _or_policy at 0x7f79cb41e8c0>, policies=[functools.partial(<function transformer_auto_wrap_policy at 0x7f79cb41e7a0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})])[32m [repeated 7x across cluster][0m
