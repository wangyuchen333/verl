#!/bin/bash
set -euo pipefail

# æ£€æŸ¥æ˜¯å¦æœ‰è®­ç»ƒè¿›ç¨‹åœ¨è¿è¡Œ
check_training_running() {
    pgrep -f "python3 -m verl.trainer.main_ppo" > /dev/null
    return $?
}

# è‡ªåŠ¨æ£€æµ‹ç©ºé—²GPUçš„å‡½æ•°
find_free_gpus() {
    nvidia-smi --query-gpu=index,memory.used,memory.total --format=csv,noheader,nounits | while IFS=, read -r index used total; do
        if [ "$used" -lt "$((total * 20 / 100))" ]; then
            echo -n "$index,"
        fi
    done | sed 's/,$//'
}

# æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„ç©ºé—²GPU
check_available_gpus() {
    FREE_GPUS=$(find_free_gpus)
    NUM_FREE=$(echo $FREE_GPUS | tr ',' '\n' | wc -l)
    if [ $NUM_FREE -gt 4 ]; then
        return 1
    else
        return 0
    fi
}

# å¯åŠ¨è®­ç»ƒçš„å‡½æ•°
start_training() {
    # ========== é…ç½®éƒ¨åˆ† ==========
    export TOKENIZERS_PARALLELISM=false
    export WANDB_API_KEY=b040deeeb597f481c025b7c7db998c32d1736333

    # è‡ªåŠ¨è®¡ç®— GPU æ•°é‡ä¸ TMP size
    N_GPUS=$(nvidia-smi -L | wc -l)
    export N_GPUS
    export TMP_SIZE=$((N_GPUS / 4))
    NUM_GPUS=$(echo $CUDA_VISIBLE_DEVICES | tr ',' '\n' | wc -l)

    if  [ $NUM_GPUS -eq 4 ]; then
        TENSOR_PARALLEL_SIZE=2
        BATCH_SIZE=4
        echo "æ£€æµ‹åˆ°4å¼ GPUï¼Œè°ƒæ•´ tensor_parallel_size=2, batch_size=4"
    elif [ $NUM_GPUS -eq 6 ]; then
        TENSOR_PARALLEL_SIZE=2
        BATCH_SIZE=6
        echo "æ£€æµ‹åˆ°6å¼ GPUï¼Œè°ƒæ•´ tensor_parallel_size=2, batch_size=6"
    elif [ $NUM_GPUS -eq 8 ]; then
        TENSOR_PARALLEL_SIZE=2
        BATCH_SIZE=8
        echo "æ£€æµ‹åˆ°8å¼ GPUï¼Œè°ƒæ•´ tensor_parallel_size=2, batch_size=8"
    else
        echo "è­¦å‘Šï¼šæœªè¯†åˆ«çš„GPUæ•°é‡ $NUM_GPUSï¼Œä½¿ç”¨é»˜è®¤è®¾ç½®"
        TENSOR_PARALLEL_SIZE=2
        BATCH_SIZE=2
    fi

    # æ—¥å¿—é…ç½®
    mkdir -p logs
    TIMESTAMP=$(date +"%Y%m%d_%H%M%S")
    LOG_FILE="logs/train_${TIMESTAMP}.log"

    # ========== å¯åŠ¨è®­ç»ƒ ==========
    echo "ğŸš€ Starting training with ${NUM_GPUS} GPUs, TMP size ${TMP_SIZE}"
    echo "ğŸ“„ Logging to $LOG_FILE"

    nohup python3 -m verl.trainer.main_ppo \
        algorithm.adv_estimator=grpo \
        data.train_files=/home/wangyc/verl/data/jec-qa-1-multi-choice/train.parquet \
        data.val_files=/home/wangyc/verl/data/jec-qa-1-multi-choice/test.parquet\
        data.train_batch_size=64 \
        data.val_batch_size=1312 \
        data.max_prompt_length=1024 \
        data.max_response_length=1024 \
        actor_rollout_ref.model.path=/home/wangyc/verl/Qwen/Qwen2.5-7B-Instruct \
        actor_rollout_ref.actor.optim.lr=1e-6 \
        actor_rollout_ref.model.use_remove_padding=True \
        actor_rollout_ref.actor.ppo_mini_batch_size=32 \
        actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=8 \
        actor_rollout_ref.actor.loss_agg_mode="seq-mean-token-sum-norm" \
        actor_rollout_ref.actor.use_kl_loss=True \
        actor_rollout_ref.actor.kl_loss_coef=0.001 \
        actor_rollout_ref.actor.kl_loss_type=low_var_kl \
        actor_rollout_ref.actor.entropy_coeff=0 \
        actor_rollout_ref.model.enable_gradient_checkpointing=True \
        actor_rollout_ref.actor.fsdp_config.param_offload=False \
        actor_rollout_ref.actor.fsdp_config.optimizer_offload=False \
        actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=32 \
        actor_rollout_ref.rollout.tensor_model_parallel_size=2 \
        actor_rollout_ref.rollout.name=vllm \
        actor_rollout_ref.rollout.gpu_memory_utilization=0.6 \
        actor_rollout_ref.rollout.n=6 \
        actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=32 \
        actor_rollout_ref.ref.fsdp_config.param_offload=True \
        algorithm.use_kl_in_reward=False \
        algorithm.norm_adv_by_std_in_grpo=False \
        trainer.critic_warmup=0 \
        trainer.logger="['console','wandb']" \
        trainer.project_name='Lawyer-Zero' \
        trainer.experiment_name='qwen2.5-7b-grpo-mcq' \
        trainer.n_gpus_per_node=$NUM_GPUS \
        trainer.nnodes=1 \
        trainer.default_local_dir=checkpoints/qwen2.5-7b-grpo-hard-mcq \
        trainer.save_freq=50 \
        trainer.test_freq=10 \
        trainer.total_epochs=2 \
        "$@" > "$LOG_FILE" 2>&1 &
}

last_status=""

while true; do
    if ! check_training_running; then
        FREE_GPUS=$(find_free_gpus)
        NUM_FREE=$(echo $FREE_GPUS | tr ',' '\n' | wc -l)
        # å–å°äºç­‰äºNUM_FREEçš„æœ€å¤§å¶æ•°ï¼Œä¸”è‡³å°‘ä¸º4
        if [ $NUM_FREE -ge 4 ]; then
            if [ $((NUM_FREE % 2)) -eq 1 ]; then
                USE_GPUS=$((NUM_FREE - 1))
            else
                USE_GPUS=$NUM_FREE
            fi
            SELECTED_GPUS=$(echo $FREE_GPUS | tr ',' '\n' | head -n $USE_GPUS | paste -sd "," -)
            export CUDA_VISIBLE_DEVICES=$SELECTED_GPUS
            if [ "$last_status" != "start" ]; then
                echo "æ‰¾åˆ°$NUM_FREEä¸ªç©ºé—²GPUï¼Œä½¿ç”¨$USE_GPUSä¸ª: $SELECTED_GPUSï¼Œå¼€å§‹è®­ç»ƒ..."
                last_status="start"
            fi
            start_training
            break
        else
            if [ "$last_status" != "wait" ]; then
                echo "ç©ºé—²GPUä¸è¶³4å¼ ï¼Œç­‰å¾…ä¸­... (å½“å‰æ—¶é—´: $(date))"
                last_status="wait"
            fi
        fi
    else
        if [ "$last_status" != "running" ]; then
            echo "è®­ç»ƒæ­£åœ¨è¿›è¡Œä¸­... (å½“å‰æ—¶é—´: $(date))"
            last_status="running"
        fi
    fi
    sleep 1
done